{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Q2 2016 DCA List of Brands to Scrape\n",
    "https://docs.google.com/spreadsheets/d/15leb475qGWrnCGqoHy78FQbe4z84B79krPpeH5IZLqI/edit\n",
    "\n",
    "### Final Google Sheet\n",
    "https://docs.google.com/spreadsheets/d/17Z6N6zJaBRVVcphy6hGTG_o7g_Q_SiCSziEYoldQsYs/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import requests library for opening webpages\n",
    "import requests\n",
    "\n",
    "# Import the BeautifulSoup object from the bs4 library\n",
    "# The object can be used directly (i.e. BeautifulSoup()); no need for bs4. prefix\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import the pandas library for data analysis and assign it an alias of \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Import Python's built-in datetime module and assign it an alias of \"dt\"\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all State Page URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time : 2016-05-16 16:24:58.684597\n",
      "End Time   : 2016-05-16 16:24:58.756382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://locations.dennys.com/AL',\n",
       " 'https://locations.dennys.com/AK',\n",
       " 'https://locations.dennys.com/AZ',\n",
       " 'https://locations.dennys.com/AR',\n",
       " 'https://locations.dennys.com/CA']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print start time -- optional\n",
    "print(\"Start Time : \" + str(dt.datetime.now()))\n",
    "\n",
    "# Create empty Python list to store all City URL pages from the main Locations page\n",
    "CityURLS = []\n",
    "\n",
    "# Use request library's .get() method to open the URL, then collect its HTML (.text)\n",
    "# Feed the HTML into a BeautifulSoup object and assign it \n",
    "HTML = requests.get(\"https://locations.dennys.com/\").text\n",
    "soup = BeautifulSoup(HTML, \"lxml\")\n",
    "\n",
    "# Find the first \"div\" HTML element with a class of \"c-directory-list\"\n",
    "container = soup.find(\"div\", {\"class\" : \"c-directory-list\"})\n",
    "\n",
    "# Within this div element, find all hyperlinks (HTML element of \"a\")\n",
    "links = container.findAll(\"a\")\n",
    "\n",
    "# Loop through each \"a\" tag (i.e. each hyperlink)\n",
    "for link in links:\n",
    "    # Get the URL (the \"href\" attribute), concatenate it to main Denny's URL\n",
    "    # Take the complete URL and append it to the CityURLS list\n",
    "    CityURLS.append(\"https://locations.dennys.com/\" + link.get(\"href\"))\n",
    "    \n",
    "# Print end time\n",
    "print(\"End Time   : \" + str(dt.datetime.now()))\n",
    "\n",
    "# Preview the first 5 results of the CityURLS list\n",
    "CityURLS[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All URLS within the State Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time : 2016-05-16 16:37:50.551641\n",
      "End Time   : 2016-05-16 16:38:07.842669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://locations.dennys.com/AL/BIRMINGHAM/248621',\n",
       " 'https://locations.dennys.com/AL/CULLMAN/248546',\n",
       " 'https://locations.dennys.com/AL/DOTHAN/209311',\n",
       " 'https://locations.dennys.com/AL/HOPE-HULL--TYSON-/209310',\n",
       " 'https://locations.dennys.com/AL/HUNTSVILLE/248545']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print start time\n",
    "print(\"Start Time : \" + str(dt.datetime.now()))\n",
    "\n",
    "# Create empty Python list to store all URL pages from each state page\n",
    "# These can either be a restaurant page or a city page -- we'll control for that in next cell\n",
    "InnerURLS = []\n",
    "\n",
    "# Loop through each CityURL\n",
    "for URL in CityURLS:\n",
    "    \n",
    "    # Open each URL with requests, feed the HTML into a BeautifulSoup object\n",
    "    HTML = requests.get(URL).text\n",
    "    soup = BeautifulSoup(HTML, \"lxml\")\n",
    "    \n",
    "    # Attempt to find the \"div\" element with a class of \"c-directory-list\",\n",
    "    # then find all hyperlinks (\"a\" tags) within the element\n",
    "    # If an error is encountered, the code in the \"except\" clause below will move to the next URL\n",
    "    try:\n",
    "        container = soup.find(\"div\", {\"class\" : \"c-directory-list\"})\n",
    "        links = container.findAll(\"a\")\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # If no error is encountered in the try: statement\n",
    "    for link in links:\n",
    "        # Loop through the links and add their URLS to the RestaurantURLS list\n",
    "        InnerURLS.append(\"https://locations.dennys.com/\" + link.get(\"href\"))\n",
    "        \n",
    "# Three of the state links from the primary Locations page are specific restaurant pages\n",
    "# This happens when a state only has 1 Denny's location\n",
    "# Manually append these three restaurant URLS to the end of our list\n",
    "InnerURLS.append(\"https://locations.dennys.com/DE/NEWARK/248777\")\n",
    "InnerURLS.append(\"https://locations.dennys.com/DC/WASHINGTON/248646\")\n",
    "InnerURLS.append(\"https://locations.dennys.com/DC/WASHINGTON/247145\")\n",
    "\n",
    "# Print end time\n",
    "print(\"End Time   : \" + str(dt.datetime.now()))\n",
    "\n",
    "# Preview the first 5 results of the CityURLS list\n",
    "InnerURLS[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Through Restaurant List -- Add to One of Two New Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://locations.dennys.com/AL/BIRMINGHAM/248621 2016-05-16 16:43:57.436631\n",
      "100 https://locations.dennys.com/CA/CLAREMONT/247811 2016-05-16 16:44:06.132505\n",
      "200 https://locations.dennys.com/CA/NO-HOLLYWOOD/200164 2016-05-16 16:44:14.200785\n",
      "300 https://locations.dennys.com/CA/TWENTYNINE-PALMS/247164 2016-05-16 16:44:21.675529\n",
      "400 https://locations.dennys.com/FL/MIAMI-GARDENS/248145 2016-05-16 16:44:29.254064\n",
      "500 https://locations.dennys.com/IL/HANOVER-PARK/247623 2016-05-16 16:44:36.702565\n",
      "600 https://locations.dennys.com/MD/FREDERICK/201848 2016-05-16 16:44:44.910933\n",
      "700 https://locations.dennys.com/NE/OMAHA/246635 2016-05-16 16:44:52.798268\n",
      "800 https://locations.dennys.com/NC/FAYETTEVILLE/248801 2016-05-16 16:45:00.733432\n",
      "900 https://locations.dennys.com/PA/CLIFTON-HEIGHTS/248776 2016-05-16 16:45:08.904494\n",
      "1000 https://locations.dennys.com/TX/KATY 2016-05-16 16:45:16.856703\n",
      "1100 https://locations.dennys.com/VA/RICHMOND 2016-05-16 16:45:24.532610\n"
     ]
    }
   ],
   "source": [
    "# Create two empty Python lists --- one will store restaurant URLS\n",
    "# The other will store any URLS that are not restaurant pages (these are city pages)\n",
    "RestaurantURLS = []\n",
    "ExtraURLS = []\n",
    "\n",
    "# For each URL in the RestaurantURLS list (which includes both restaurant and city pages)\n",
    "for URL in InnerURLS:\n",
    "    \n",
    "    # Find the numeric location of the URL in the RestaurantURLS list\n",
    "    # If the location is evenly divisible by 100, print the location, the URL, and the current time\n",
    "    location = InnerURLS.index(URL)\n",
    "    if location % 100 == 0:\n",
    "        print location, URL, dt.datetime.now()\n",
    "    \n",
    "    # Open the URL and feed the HTML content to BeautifulSoup\n",
    "    HTML = requests.get(URL).text\n",
    "    soup = BeautifulSoup(HTML, \"lxml\")\n",
    "    \n",
    "    try:\n",
    "        # If the h1 element can be found, it's a restaurant page\n",
    "        # Add it to the FinalRestaurantsURL list\n",
    "        Name = soup.find(\"h1\", {\"itemprop\": \"name\"}).text.strip()\n",
    "        RestaurantURLS.append(URL)\n",
    "    except:\n",
    "        # Otherwise, if an error is encountered, it's a city page\n",
    "        # Add it to the ExtraURLS list\n",
    "        ExtraURLS.append(URL)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Extra Restaurant URLS from City Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Every extra URL that failed in the previous cell is a city page\n",
    "# For each of these extra URLS,\n",
    "for URL in ExtraURLS:\n",
    "    \n",
    "    # Open each of the ExtraURLS and parse the HTML\n",
    "    HTML = requests.get(URL).text\n",
    "    soup = BeautifulSoup(HTML, \"lxml\")\n",
    "    \n",
    "    # Find the \"div\" element with a class of \"c-location-grid-item-link-wrapper\"\n",
    "    # This is the container of each restaurant page\n",
    "    restaurants = soup.findAll(\"div\", {\"class\" : \"c-location-grid-item-link-wrapper\"})\n",
    "    \n",
    "    # Get the URLS of each restaurant within the container\n",
    "    # Add each URL to the RestaurantsURL list we created earlier\n",
    "    # This list already contains the restaurant pages from the previous cell\n",
    "    # The [3:] removes extra characters (backslashes) from the URL\n",
    "    for x in restaurants:\n",
    "        RestaurantURLS.append(\"https://locations.dennys.com/\" + x.find(\"a\").get(\"href\")[3:])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Phone</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Address, City, State, Zipcode, Phone, URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Python list of strings that will serve as DataFrame column names\n",
    "columns = [\"Name\", \"Address\", \"City\", \"State\", \"Zipcode\", \"Phone\", \"URL\"]\n",
    "\n",
    "# Initialize DataFrame, feed the \"columns\" list to the columns parameter\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Preview empty DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RestaurantURLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://locations.dennys.com/AL/BIRMINGHAM/248621 2016-05-16 16:49:11.162051\n",
      "100 https://locations.dennys.com/CA/EUREKA/247449 2016-05-16 16:49:22.488496\n",
      "200 https://locations.dennys.com/CA/SAN-FERNANDO/247847 2016-05-16 16:49:33.007418\n",
      "300 https://locations.dennys.com/FL/HIALEAH-GARDENS/247302 2016-05-16 16:49:43.914673\n",
      "400 https://locations.dennys.com/IL/GLEN-CARBON/247220 2016-05-16 16:49:53.650213\n",
      "500 https://locations.dennys.com/MD/NORTH-EAST/248614 2016-05-16 16:50:04.711588\n",
      "600 https://locations.dennys.com/NJ/CLEMENTON/248813 2016-05-16 16:50:15.373411\n",
      "700 https://locations.dennys.com/OH/BOARDMAN-TWP/247402 2016-05-16 16:50:27.211383\n",
      "800 https://locations.dennys.com/SC/NORTH-CHARLESTON/247987 2016-05-16 16:50:39.984877\n",
      "900 https://locations.dennys.com/UT/LOGAN/249268 2016-05-16 16:50:51.453567\n",
      "1000 https://locations.dennys.com/AZ/FLAGSTAFF/247973 2016-05-16 16:51:05.317046\n",
      "1100 https://locations.dennys.com/CA/FRESNO/247815 2016-05-16 16:51:19.515351\n",
      "1200 https://locations.dennys.com/CA/SAN-JOSE/247442 2016-05-16 16:51:34.448198\n",
      "1300 https://locations.dennys.com/FL/PEMBROKE-PINES/248692 2016-05-16 16:51:53.500177\n",
      "1400 https://locations.dennys.com/NM/LAS-CRUCES/248877 2016-05-16 16:52:12.583509\n",
      "1500 https://locations.dennys.com/TX/HOUSTON/247570 2016-05-16 16:52:26.435127\n"
     ]
    }
   ],
   "source": [
    "# For each of the 1585 URLS in the RestaurantURLS list\n",
    "for URL in RestaurantURLS:\n",
    "    \n",
    "    # Do the same test to print the list position, URL, and time for every 100th URL\n",
    "    location = RestaurantURLS.index(URL)\n",
    "    if location % 100 == 0:\n",
    "        print location, URL, dt.datetime.now()\n",
    "    \n",
    "    # Open and parse the page\n",
    "    HTML = requests.get(URL).text\n",
    "    soup = BeautifulSoup(HTML, \"lxml\")\n",
    "    \n",
    "    # Find the HTML elements on the page that contain the data bits we're looking for\n",
    "    # Use the .text attribute of each element to get the element's contents\n",
    "    # Use Python's built-in .strip() string function to remove extra white space\n",
    "    # Store each data point in its own variable (Name, Address, City etc.)\n",
    "    Name      = soup.find(\"h1\", {\"itemprop\": \"name\"}).text.strip()\n",
    "    Address   = soup.find(\"span\", {\"itemprop\" : \"streetAddress\"}).text.strip()\n",
    "    City      = soup.find(\"span\", {\"itemprop\" : \"addressLocality\"}).text.strip()\n",
    "    State     = soup.find(\"span\", {\"itemprop\" : \"addressRegion\"}).text.strip()\n",
    "    ZipCode   = soup.find(\"span\", {\"itemprop\" : \"postalCode\"}).text.strip()\n",
    "    Telephone = soup.find(\"span\", {\"itemprop\" : \"telephone\"}).text.strip()\n",
    "    \n",
    "    # Package the DataFrame header names and the values for each URL\n",
    "    # in a Python dictionary object (stored in variable also called \"dictionary\")\n",
    "    # The keys are the DataFrame column names\n",
    "    # The values are the variable that are storing the values\n",
    "    dictionary = {\"Name\" : Name, \"Address\" : Address, \n",
    "                  \"City\" : City, \"State\" : State, \"Zipcode\" : ZipCode, \n",
    "                  \"Phone\" : Telephone, \"URL\" : URL}\n",
    "    \n",
    "    # Append the dictionary to the end of the \"df\" DataFrame\n",
    "    df = df.append(dictionary, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove duplicates from DataFrame (just in case), alter it in place\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Sort by state, then city, then name (Alphabetical for each)\n",
    "df.sort([\"State\", \"City\", \"Name\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export to a CSV file, do not include the index to the left of DataFrame\n",
    "# The encoding parameter avoids common issues with foreign characters\n",
    "df.to_csv(\"Q2.16 DCA Scrape.csv\", index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
