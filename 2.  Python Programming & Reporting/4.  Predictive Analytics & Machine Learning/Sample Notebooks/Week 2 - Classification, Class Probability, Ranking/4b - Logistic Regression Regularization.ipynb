{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script illustrates the effects of regularization for Logistic Regression. \n",
    "\n",
    "%matplotlib inline\n",
    "# import necessary libraries and specify that graphs should be plotted inline. \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data set\n",
    "# See '2 - Decision Trees' for a description of this data set\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-process the data set\n",
    "\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "# Centering and scaling happen independently on each feature by computing the relevant statistics on the samples\n",
    "# in the training set. Mean and standard deviation are then stored to be used on later data using the transform\n",
    "# method.\n",
    "# Standardization of a dataset is a common requirement for many machine learning estimators: they might behave\n",
    "# badly if the individual feature do not more or less look like standard normally distributed data (e.g. Gaussian\n",
    "# with 0 mean and unit variance).\n",
    "# For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of\n",
    "# Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered\n",
    "# around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger\n",
    "# that others, it might dominate the objective function and make the estimator unable to learn from other features\n",
    "# correctly as expected.\n",
    "\n",
    "# classify small against large digits (i.e., convert the task from multi-class classification to binary classification)\n",
    "y = (y > 4).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100.00\n",
      "Sparsity with L1 penalty: 4.69%\n",
      "score with L1 penalty: 0.9098\n",
      "Sparsity with L2 penalty: 4.69%\n",
      "score with L2 penalty: 0.9098\n",
      "C=1.00\n",
      "Sparsity with L1 penalty: 9.38%\n",
      "score with L1 penalty: 0.9098\n",
      "Sparsity with L2 penalty: 4.69%\n",
      "score with L2 penalty: 0.9093\n",
      "C=0.01\n",
      "Sparsity with L1 penalty: 85.94%\n",
      "score with L1 penalty: 0.8609\n",
      "Sparsity with L2 penalty: 4.69%\n",
      "score with L2 penalty: 0.8915\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD7CAYAAAB9sLH/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFQlJREFUeJzt3X+QFPWZBvDnYYHlR0CBJQbYdVcEVDQHhF8mKIpKFqgSsRLNJZfSyJ3EcCm5XJEqQ0VDRQu9VKVyZV0q8QIkgOdJlCSkIhYg6IEIhJ8HwolAlGQlQRRFYBfYhff+2CYZ2Zm332EHFobnUzXFbj/dPb3Ud5/t6enppplBRCRNq5beABG5MKgsRCREZSEiISoLEQlRWYhIiMpCREIuurIg+QuSj7X0dogU2tke23mXBcm3Sd6WZXpbks8nuZG8uSBbeBaRvJlkTUtvh5wfnLF9PcmlJA+Q3E/yOZI9WmIbo87G2C70nsWrAL4K4C8FXq9IS+oC4D8BVAGoBHAIwM9bcoNaQsHKwsyOm9m/m9mrAE6kzU/yFZKPk/w9yYMkF5LsmpFfT/I1kh+S/N/MPZVk2UdJriJ5iOQSkmUZ+XMk/5KsdwXJa7M8f0cALwLoSfJw8uhJspZkt4z5Bid/Tdqc+f+OXMjM7EUze87MPjKzWgD/AWBErvmLdWy39DGLewBMBNATQAOAJwGAZC8ALwB4DEBXAFMBLCDZPWPZrwC4D8AnAbRN5jnlRQB9k2wjgP86/YnN7AiAsQD2mtknksdeAK8AuDtj1q8CeNbM6pv7w0rRGAlgW8o8RTe2W7os5pnZ68kP9zCAu0mWoPGHWGRmi8zspJktBbAewLiMZX9uZm+aWR2AXwIYeCows9lmdsjMjgGYDmAAyUuC2zQneX4k2/JlAPOa92NKsSD5dwAeAfDtlFmLbmy3dFn8KePrPQDaAChD4+vCu5LdtA9JfgjgBgCZB5Uyj4vUAvgE0PifQPIJkrtJfgTg7WSeMsQsBNCfZG8AowEcNLPf5/lzSREi2QeNf9mnmNnKlNmLbmy3js54llRkfH05gHoA76HxP3qemd1/Buv8CoA7ANyGxv/MSwB8AIBZ5m3ykVszO0rylwD+AcDV0F6FACBZCeAlAI+aWWRMFN3YPtM9izYk22U8WgMAyVKS7ZJ52iZZth/klK+S7E+yA4DvA3jezE4AeBrA7SSrkzZtl7wVVB7Ytk4AjgF4H0AHADOcefcB6JZlN24ugK8BGJ9si1w8mozt5DjDcgA/NrOfBtdTdGP7TMtiEYC6jMf0ZPqO5PteABYnX1c665kH4Bdo3O1qB+BBADCzP6GxQacB2I/GNv52cHvnonG37x0A2wGsyTWjmb0B4L8B/CHZJeyZTF8F4CSAjWb2duA5pXhkG9v/BKA3gO9lvLtwOGU9RTe22VIXvyH5CoCnzWxmi2xACpLLATxzvm6fnL+KdWy39DGL8xLJoQA+g8a/ACJFozlju6XfDTnvkJyDxgNZ/2Jmh1p6e0QKpblju8VehojIhUV7FiISorIQkZC8DnCWlZVZVVVVzvzwYf/dpFat/G5q166dm3/44YduXltb6+Zt27ZtVr579+73zKy7O5NccNLG9cGDB93l08ZNaWmpm6eN67Tfqw4dOrh52vbt3LkzNK7zKouqqiqsX78+Z75ypX8GbNoPddVVV7n57373OzffsGGDm1dWeqd8ABUVFW4+YcKEPe4MckFKG9dp4+7yyy938z59+rj5woUL3XzVqlVuPmDAADdPG/fV1dWhca2XISISorIQkRCVhYiEqCxEJERlISIhKgsRCcnrrdPa2lr37cmnnnrKXd6/tAUwduxYN7/mmmvcvKGhwc1vvfVWN2/fvr2bS3E6cuQI1q1blzOfPXu2u3zr1v6v0Re+8AU3v+6669z8+PHjbn7LLbe4edp5HlHasxCREJWFiISoLEQkRGUhIiEqCxEJUVmISIjKQkRC8jrPorS0FH379s2ZV1dXu8s/8sgjzcr79evn5r/61a/c/KWXXnJz75oGUrzatWvnjq1x48blzADgsccec/Mf/vCHbp72EfdnnnnGzZctW+bmvXv3dvMo7VmISIjKQkRCVBYiEqKykKxIforks8kdu7eTXETSP2iUvs6RJDeSbCD5xdOye0nuTB73ZkwfTHIryV0kn8x271w2ejKZZwvJz6StV/KnspAmkl/IXwN4xcyuNLP+aLw352XNXPUf0XhT3o8dsSPZFcD3AAwHMAyN9xTtksQ/ATAJQN/kMSbLesdm5JOSZdLWK3lSWUg2owDUZ94x3Mw2m5l/ReYUZva2mW1B4415M1UDWGpmB8zsAwBLAYwh2QNAZzNbbY13w5oLYEKWVd8BYK41WgPg0mTZrOttzs9wMdO9TiWb6wD4l0pPkFwJoFOWaKqZ+e9V/00vNN5N/JSaZFqv5OvTp+ezfLbpcgbyvp7Fxo0bc+Zbt251l0+75HnaeRTecwPA5z73OTefNGmSm6e9Xy1NmdmNBVhNtgudmDO9oMvX1dW5Y3fLli05MwB4/vnn3TztPIq0W2jcdNNNbv7ggw+6+VtvveXmUXoZItlsAzA4MiPJlSQ3Z3nclsfz1QDIvGlLOYC9yfTyLNPzWT7bdDkDKgvJZjmAUpL3n5pAcijJJn/izOxGMxuY5RF9CQIAiwF8nmSX5ADk5wEsNrM/AzhE8vrkoOs9ALLtnv4WwD3JuyLXAziYLJt1vXlsl2RQWUgTycHEOwGMTt463QZgOpr5VzkpnBoAdwF4KlkvzOwAgEcBrEse30+mAcA3AMwEsAvAbgAvJut6gOQDyTyLAPwhmednACYH1it50gFOycrM9gK4u8DrXIePv6zIzGYDaHKxSzNbj8YDrqdPz3ynxgD8cz7rlfxpz0JEQlQWIhKishCREDa+3IsZMmSIebemb9XK75533nnHzXv27OnmDz30kJtPmTLFzfft2+fmabeuJ7nBzIa4M8kFJ21cp91P5siRI25eUlLi5vfdd5+bP/HEE27+7rvvunnafUmi41p7FiISorIQkRCVhYiEqCxEJERlISIhKgsRCVFZiEhIXp8NOXDggHsPg7q6Onf5JUuWuPlrr73m5mnnUaRdD6O8POvHEv5qzZo1bi7Fqa6uDq+//nrOPO08irlz57r5b37zGzdPG9dpy6edn5TPuVQe7VmISIjKQkRCVBYiEqKyEJEQlYWIhKgsRCREZSEiIXmdZ3HppZdi/PjxOfPjx4+7y19xxRVunnaexbp169x85syZbr5ixQo3nzx5sptL8fLORaitrXWXHTFihJuvXr3azffs2ePmgwYNcvO035vq6mo3j9KehYiEqCxEJERlISIhKgsRCVFZiEiIykJEQlQWIhKS971OvXuDzJ8/3132lltucfNrrrnGzdPez964caObDxs2zM3HjRvn5lKc2rRpgx49euTMZ8/2b5U6evRoN+/Vq5ebjxw50s29a20AwLXXXuvmafclidKehYiEqCxEJERlISIhKgsRCVFZiEiIykJEQlQWIhLCfO4pQHI/AP/D98Wt0sy6t/RGSGFpXMfGdV5lISIXL70MEZEQlYWIhKgsRCREZSEiISoLEQlRWYhIiMpCREJUFiISorIQkRCVhYiEqCxEJCSvC/aWlZVZVVVVzvzo0aPu8mmfQ2nXrp2bf/TRR25+6NAhN2/btq2bd+zY0c3feOON9/RBsuKTNq4PHz7sLl9SUuLmpaWlbn7w4EE3T3v+9u3bu3na79WOHTtC4zqvsqiqqsL69etz5m+++aa7fNpd1vv16+fmixcvdvNXX33VzSsqKtx8+PDhbj5s2LCL+ZOJRSttXK9YscJdvmvXrm7eu3dvN3/hhRfcPO0u7GlXxb/66qvdfOTIkaFxrZchIhKishCREJWFiISoLEQkRGUhIiEqCxEJyeut07q6OmzZsiVnPm/ePHf5999/380nTJjg5n379nXzY8eOuXnajZlPnDjh5lKcamtr3Ztqz5o1y10+bdzceeedbn7VVVe5eX19vZvfdNNNbp52HkiU9ixEJERlISIhKgsRCVFZiEiIykJEQlQWIhKishCRkLzOsygtLUWfPn1y5qNGjXKXnzp1qptPnz7dzSsrK9186dKlbr58+XI3965pIMWrtLQUV155Zc68urraXf7RRx918xkzZrh52rhesGCBm7/88stuXqhxrT0LEQlRWYhIiMpCREJUFpIVyU+RfJbkbpLbSS4i6V/3MH2dI0luJNlA8ovOfINJbiW5i+STJJlM70pyKcmdyb9dmrM9kh+VhTSR/HL+GsArZnalmfUHMA3AZc1c9R8BfA3AMynz/QTAJAB9k8eYZPpDAJaZWV8Ay5Lv5RxRWUg2owDUm9lPT00ws81mtrI5KzWzt81sC4CTueYh2QNAZzNbbY2Xg58L4NTHke8AMCf5ek7GdDkH8nrrVC4a1wHYEJmR5EoAnbJEU83spTN47l4AajK+r0mmAcBlZvZnADCzP5P85BmsX85QXmVx7Ngx7N69O2fuXRMAAObPn+/mae83b9261c1vv/12N//Sl77k5u+++66bS1NmdmOBV8lsT1Pg5/iYo0ePurex2LRpk7v8nDlz3DxtXK9Zs8bNx4wZ4+aTJk1y83379rl5lPYsJJttAHIegMx0FvYsagCUZ3xfDmBv8vU+kj2SvYoeANTu55COWUg2ywGUkrz/1ASSQ0k2uSSTmd1oZgOzPM6kKJC8zDhE8vrkQOs9ABYm8W8B3Jt8fW/GdDkHVBbSRHJg8U4Ao5O3TrcBmI6//YU/I0nh1AC4C8BTyXpPZZszZv0GgJkAdgHYDeDFZPoTyTbtBDA6+V7OEb0MkazMbC+Auwu8znX4+EuMzGxgxtfr0XiQ9fR53gdwayG3SeK0ZyEiISoLEQlRWYhICBuPZcUMGTLEvFvTt2/f3l1+586dbl5RUeHmP/jBD9z861//upvv2ePfWf7Tn/60m5PcYGZD3JnkgpM2rjt37uwuv3evf9y3U6ds7yz/zbe+9S03/853vuPm+/fvd/P+/fu7eXRca89CREJUFiISorIQkRCVhYiEqCxEJERlISIhKgsRCcnrsyEnTpzABx98kDOvra11l1+2bJmbb9++3c3T3m9Ouz9Cjx493DztPBApTkePHsWOHTty5gcPHnSXf+6559x8yZIlbj5t2jQ3Tzv/p2fPnm5eX1/v5lHasxCREJWFiISoLEQkRGUhIiEqCxEJUVmISIjKQkRC8jrPoqSkBF265L69ZF1dnbt8eXnWyy/+1erVq9184UL/Ys6PP/64m69du9bNb7jhBjeX4tSqVSv3WixHjhxxlx80aJCbp40771oaQPp5FmnLV1dXu3mU9ixEJERlISIhKgsRCVFZiEiIykJEQlQWIhKishCRkILe63TFihVuPmSIf2uCAQMGuPnNN9/s5lu2bGnW80+cONHNpTiVlJTgkksuyZkvWLDAXX7EiBFuXllZ6eajRo1y87TrrKTdF+SBBx5w8yjtWYhIiMpCREJUFiISorIQkRCVhYiEqCxEJERlISIhNLP4zOR+AHvO3uac9yrNrHtLb4QUlsZ1bFznVRYicvHSyxARCVFZiEiIykJEQlQWIhKishCREJWFiISoLEQkRGUhIiEqCxEJUVmISEhe1+AsKyuzqqqqs7QpzVdbW+vmJSUlbl5aWurmGzZseE+fDSk+aeM67SMRaXmrVv7f5OPHj7v5sWPH3DxNx44d3XzTpk2hcZ1XWVRVVaXehLUlbdq0yc29i7ICQO/evd2c5MX8YaOilTau035ZGxoa3Dztl7WmpsbNd+zY4eZpZTR8+HA379ixY2hc62WIiISoLEQkRGUhIiEqCxEJUVmISIjKQkRCCnqv05Y2aNCglt4EuQA1NDTgwIEDOfN9+/a5y7/11ltuPnjwYDdPW//AgQPd/MSJE25eX1/v5lHasxCREJWFiISoLEQkRGUhIiEqCxEJUVmISIjKQkRCzul5Fi+//LKbjxo1ys1nzJjh5tOmTct7m0RKSkrcj5GXl5e7y69du7ZZz79gwQI3nzJlipsfOnTIzdM+Ih+lPQsRCVFZiEiIykJEQlQWIhKispCsSH6K5LMkd5PcTnIRyX7NXGcpyfkkd5FcS7Iqx3xjSO5I5nsoY/o3k2lGsqw52yL5U1lIEyQJ4NcAXjGzK82sP4BpAC5r5qr/EcAHZtYHwI8A/FuW5y4B8GMAYwH0B/Blkv2TeBWA2wDowsktQGUh2YwCUG9mPz01wcw2m9nKZq73DgBzkq+fB3BrUkyZhgHYZWZ/MLPjAJ5NloOZbTKzt5u5DXKGzul5FmnnUTz99NNurvMozpnrAGyIzEhyJYBOWaKpZvbSadN6AfgTAJhZA8mDALoBeC/bPIkaAP617Jvp5MmT7j1ndu7c6S6fdi+dWbNmufnUqVPdfPPmzW5eVua/Iku7X05UUV38Rs49M7sxj9lP34sAgNPv0BOZR1qAykKy2Qbgi5EZ89yzqAFQAaCGZGsAlwA4/RJVp+Y5pRzA3si2yNmlspBslgOYQfJ+M/sZAJAcCqCDmf1P5ox57ln8FsC9AFajsYyWW9N7/60D0JfkFQDeAfD3AL5yZj+GFJIOcEoTyS/wnQBGJ2+dbgMwHc3/Cz8LQDeSuwD8K4CHAIBkT5KLkuduAPBNAIsB/B+AX5rZtmS+B0nWoHFvYwvJmc3cHsmD9iwkKzPbC+DuAq/zKIC7cjzXuIzvFwFYlGW+JwE8WchtkjjtWYhIiMpCREIK+jJk3bp1bj506FA37969eyE3RySkpKQEXbp0yZmvWrXKXX706NFu3qFDBzfv3Lmzm3/2s5918zZt2rh569aF+TXXnoWIhKgsRCREZSEiISoLEQlRWYhIiMpCREJUFiISUtDzLNLOo0hTXV1doC0RiTMzNDQ05MzHjx/vLt+tWzc3nzx5spt719IAgCNHjjQr79Qp24eC86c9CxEJUVmISIjKQkRCVBYiEqKyEJEQlYWIhKgsRCTkgrqs3sSJE9189uzZ52hLpJiQRKtWuf9uVlRU5MwAoL6+3s337vUvXfrwww+7+Xe/+103T7ueRdr1NKK0ZyEiISoLEQlRWYhIiMpCREJUFiISorIQkRCVhYiEXFDnWUyZMqWlN0GKkJnh5MmTOfO08yhKSkrcvKyszM3Hjh3brOXT7Nq1q1nLn6I9CxEJUVmISIjKQkRCVBYiEqKyEJEQlYWIhKgsRCSEZhafmdwPYM/Z25zzXqWZdW/pjZDC0riOjeu8ykJELl56GSIiISoLEQlRWYhIiMpCREJUFiISorIQkRCVhYiEqCxEJERlISIh/w+tINqFdrmABQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set regularization parameter\n",
    "for i, C in enumerate((100, 1, 0.01)):\n",
    "    # we create an instance of the Classifier\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = linear_model.LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR = linear_model.LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    \n",
    "\n",
    "    # Train the model (fit the data)    \n",
    "    clf_l1_LR.fit(X, y)\n",
    "    clf_l2_LR.fit(X, y)\n",
    "\n",
    "    # Get the coefficients of the models\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the L1 sparsity inducing norm\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)\n",
    "    print(\"score with L1 penalty: %.4f\" % clf_l1_LR.score(X, y))\n",
    "    print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_l2_LR)\n",
    "    print(\"score with L2 penalty: %.4f\" % clf_l2_LR.score(X, y))\n",
    "    # score() returns the mean accuracy on the given test data and labels.\n",
    "    \n",
    "    l1_plot = plt.subplot(3, 2, 2 * i + 1)\n",
    "    l2_plot = plt.subplot(3, 2, 2 * (i + 1))\n",
    "    if i == 0:\n",
    "        l1_plot.set_title(\"L1 penalty\")\n",
    "        l2_plot.set_title(\"L2 penalty\")\n",
    "\n",
    "    l1_plot.imshow(np.abs(coef_l1_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                   cmap='binary', vmax=1, vmin=0)\n",
    "    l2_plot.imshow(np.abs(coef_l2_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                   cmap='binary', vmax=1, vmin=0)\n",
    "    plt.text(-8, 3, \"C = %.2f\" % C)\n",
    "\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l2_plot.set_xticks(())\n",
    "    l2_plot.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What differences do you observe between L1 and L2 regularization?\n",
    "\n",
    "# The C parameter controls the amount of regularization in the LogisticRegression object: a large value\n",
    "# for C results in less regularization. penalty=\"l2\" gives Shrinkage (i.e. non-sparse coefficients), while\n",
    "# penalty=\"l1\" gives Sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
